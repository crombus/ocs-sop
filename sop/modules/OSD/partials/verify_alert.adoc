
*Verify the alert is still active.*

.Step 1: Get the route to this cluster's alertmanager:
[source,shell]
----
MYALERTMANAGER=$(oc -n openshift-monitoring get routes/alertmanager-main --no-headers | awk '{print $2}')
----


.Step 2: Get your alertname from the alert, set for use in jq:
[source,shell]
----
export MYALERTNAME="<alertname from alert>"
----

.Step 3: Check if the alert is still active:
[source,shell]
----
curl -k -H "Authorization: Bearer $(oc -n openshift-monitoring sa get-token prometheus-k8s)"  https://${MYALERTMANAGER}/api/v1/alerts | jq '.data[] | select( .labels.alertname | test(env.MYALERTNAME)) | { ALERT: .labels.alertname, STATE: .status.state}'
----

No entries means the alert is no longer active. 

Some alerts, such as mismatch versions, can occur during upgrades and resolve themselves. If this alert is not a mismatch version alert then there should be an investigation into what triggered the alert even though the alert resolved. Look for other active alerts or alerts with similiar timing. 

.Step 4: If you need more details run:
[source,shell]
----
curl -k -H "Authorization: Bearer $(oc -n openshift-monitoring sa get-token prometheus-k8s)"  https://${MYALERTMANAGER}/api/v1/alerts | jq '.data[] | select( .labels.alertname | test(env.MYALERTNAME)) | { ALERTDETAILS: .}'
----

More about the Prometheus Alert endpoint can be found here:
https://prometheus.io/docs/prometheus/latest/querying/api/#alerts


